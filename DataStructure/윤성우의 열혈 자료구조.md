#윤성우의 열혈 자료구조
Sungwon park이 자료구조 학습을 다시 시작했습니다.

##Chapter1
###책과 강의소개
대부분의 공대생 마인드 : 이론 -> 구현

자료구조는 이론중심적 과목이다. 하지만 우리는 이 이론을 배우고 어떻게 구현이 되는지 알고 싶다. 따라서 이 책은 공대생들에게 이론을 배우고 잘 쓸수 있도록 도와주기 위해 지필했다. 대부분 사람들이 구현을 중요시하고 그 다음 이론을 알고 구현을 통해서 이론을 알아가는 과정은 굉장히 위험한 프로세스이다. 이론을 정확히 이해하고 구현하는 생각을 가져야 한다. 자료구조는 이론이 굉장히 중요하다.

###01-1 자료구조에 대한 기본적인 이해
이 책을 읽기 위해서는 기본적은 C문법에 대해서 다 알고 있다고 가정을 하지만, 필요에 의해서 문법을 생각하기 때문에 다 기억할 수는 없다. 따라서 책을 공부하면서 굉장히 필요성을 많이 느낄꺼고 그때마다 해당 문법을 완성해 나가면서 공부하면 되겠다.

자료구조란 무엇일까? 자료구조는 데이터의 표현, 저장이라고도 말한다. 책에서는 자료구조와 알고리즘에 대한 언급이 계속해서 나올것이다. 왜냐하면 프로그램이라는것이 데이터를 어떻게 잘 표현해서(자료구조) 데이터를 내가 원하는 목적에 맞게 처리하는 것(알고리즘)이기때문이다. 

자료구조에는 여러가지 종류가 있다, 선형구조, 비선형구조, 파일구조, 단순 구조 등이 있다. 대부분 학생들이 선형구조에서 멈추고 비선형구조까지는 공부를 못하는 사람들이 굉장히 많다. 따라서 이 책에서는 비선형까지 공부하기를 원한다. 시간이 오래걸려도 말이다.

자료구조와 알고리즘의 예시

자료구조의 표현 (배열), 왜 배열을 이용해서 아래에 있는 숫자들을 넣었을까?(목적이 있어야함) -> 목적(합을 구하기 위해서)
```C
int arr[10] = {1,2,3,4,5,6,7,8,9,10}
```

알고리즘(데이터의 처리) -> 합을 구하기 위한 알고리즘
```C
for (idx = 0; idx < 10; idx++) {
	sum += arr[idx];
}
```

위 코드를 보면 알겠지만, 자료구조가 결정되고 알고리즘을 통해 처리하는 모습을 볼 수 있다. 결과론적으로 "알고리즘은 자료구조에 의존적이다."

자료구조는 모델 자체에 대한 이해 중심 학습이다(이론을 나타냄) 그리고 코드 레벨에서 자료구조 구현 중심 학습이다.(책에서)

자료구조의 모델을 그림으로 우선 이해해야 하므로, 그림을 많이 그리는 연습을 하자. 그리고 단순히 책에 나와있는 코드를 줄줄이 읽는것도 좋기는 하지만, 그것으로 만족하면 남는것이 없다. 따라서 코드를 통째로 보는것보다 코드 중간중간을 비워서 삽입하는 능동적인 학습을 하자.

자료구조 구현이 가능해야하만 의미가 있는것은 아니니 걱정하지 말자.

###01-2 알고리즘의 성능분석 방법
알고리즘의 성능분석이라고 했지만, 이 분석방법이 자료구조에서도 쓰이니 주제에 대해서 너무 깊이 생각하지 말자.

알고리즘의 성능분석은 약간의 수학적 지식이 필요한데 아래와 같다
<pre><code>지수식 => y = 2의 X제곱
로그식 => y = log2X
</code></pre>
Y는 시간을 나타내고, x는 데이터의 개수를 나타낸다

지수함수와 로그함수 그래프를 통해서 한눈에 알고리즘의 성능을 파악할 수 있다.

평가하는 방법은 두가지가 있는데, 하나는 시간복잡도와 또 하나는 공간 복잡도가 있다. 그렇지만 거의 시간복잡도를 많이 사용한다. 왜냐하면 공간복잡도는 얼마만큼 메모리를 적게사용하냐를 판단하는데 이 판단은 미미하다 메모리를 접근할때 사용되는 시간이 더욱더 걸리므로 그리고 감을 믿자, 일반적으로 사용자가 느끼기에 반응이 빨라야 빠른 프로그램이라고 판단한다. 따라서 시간이 얼마만큼 걸리는지에 대한 생각이 빠른 프로그램이라고 판단하는 기준에 맞다고 생각한다.

그러면 어떻게 속도를 판단할까? -> 특정 중심이 되는 연산 횟수를 구하면 된다 하지만 어떤것이 특정 줌심이 되는 연산인지는 정확히 파악하는데 어려움이 있다. 하지만 너무 어렵게 생각하지 말고 가볍게 넘어가자.

위 기준을 통해서 T(n)이라는 시간의 복잡도 함수를 만들어 그래프를 표현하면 한눈에 해당 알고리즘의 성능을 판단할 수 있다.

####최악의 경우
연산 횟수가 극히 낮은 상황이라면 어떤 알고리즘도 대부분 만족하기 때문에 판단하기가 어렵지만. 최악의 경우일 경우에는 판단하기가 쉽다. 왜냐하면 항상 그 알고리즘의 최악의 경우는 정해져 있기 때문이다. 두 알고리즘을 평가할때 최악의 경우를 비교했을때, 어떤것이 더 시간이 걸리지 않는다를 비교해서 더 좋은 알고리즘을 찾을 수 있다. 평균적인 경우도 구할 수 있지만. 구하기가 굉장히 복잡하고. 또 구했다고 하더라도 그 값이 정확하다는 보장이 없고 증명하기가 어렵다. 따라서 대부분의 디폴트 평가는 최악의 경우로 판단한다.

####평균적인 경우
앞에서도 언급했지만, 평균적인 경우를 구하는것 자체가 무의미하고, 어렵고, 증명도 어렵다. 그 이유에 대해 조금더 자세히 알아보자.

가정 1. 탐색 대상이 배열에 존재하지 않을 확률을 50%(발생할 확률도 50%라는 얘기)라고 가정하자.
가정 2. 배열의 첫 요소부터 마지막 요소까지, 탐색 대상이 존재할 확률은 동일하다 => 이 말은 어느 위치에 있던 존재하는 확률은 모든 요소가 동일하게 갖고 있다란 의미다.

n크기의 배열에서 원하는 요소를 검색한다고 가정할때

* 탐색 대상이 존재하지 않은 경우의 연산횟수 -> N번 (마지막까지 발견하지 못할 수 도 있음)
* 탐색 대상이 존재하는 경우의 연산횟수 N/2번 (중간에서 발견될수도 있고 첫번째또는 마지막까지 탐색할 수 도 있음)

각각의 요소들의 발생할지 안할지의 확률은 50%이니 각각의 값에 1/2를 곱한다.
n * 1/2 + n/2 * 1/2 = 3N/4

지금 이 수식까지 뽑아내는데 손이 많이 가는 작업이다. 그리고 저 수식이 정확하다는 보장도 할 수 없다. 

####이진 탐색 알고리즘
일단 탐색하고자 하는곳이 정렬이 되어있어야 한다. 어떠한 기준에 따라 정렬만 되어있으면 된다. 해당 배열에 중간에 위치하는 인덱스를 추출하여 해당 값을 가리키고 해당 값과 내가 찾고하자는 값이 동일한지 판단한다. 동일하지 않다면 둘의 크기를 구해서 내가 구하고자 하는 값이 중간에 위치한 값보다 큰지 작은지 판단하고 크다면 중간에서 오른쪽 영억을, 작다면 중간에서 왼쪽 영역을 잡고 비교를 한다. 이 판단을 계속해서 반복하며 내가 원하는 값을 찾는 알고리즘이다.

두개의 인덱스를 활용하여 (first, last) 찾고자하는 영역의 범위를 결정해줄 수 있다. 이 범위가 만약 fisrt <= last라는 조건에 만족한다면 찾지 못하고 튕겨저 나간다. 이미 내가 찾는 범위를 초과한 상황이다. 

중앙 값을 mid라는 변수로 가정했을때, 크기가 크면 mid + 1을 하여 first에 삽입, 반대의 경우면 mid - 1을 하여 last에 삽입한다. 왜 이렇게 할까? 일단 내가 비교한 mid위치의 값은 비교가 이미 된 상태이다. 따라서 비교를 하지 않고 제외 시키고 나머지 값들과 비교를 해야한다. 만약에 저렇게 하지 않는다면 내가 비교한 값을 계속해서 비교하게되고 무한루프로 빠지게 될 수 있다. 

####이진 탐색 알고리즘의 시간 복잡도 구하기
시간 복잡도를 구하기 위해선 어떻게 동작하는지 예시 숫자를 넣어가며 나누어보면 된다. 결과적으로 일반화 하면 다음과 같다
데이터 수가 N개이고 이 N이 1이 되기까지 2로 나눈 횟수 K회 진행 그리고 데이터가 1개 남았을때 비교연산 1회 진행
T(n) = k + 1이 나온다 하지만 K는 구하지 않았다. N * 1/2 k승 = 1 수식을 구하면 T(n) = log2N이 나온다. 다음시간에는 빅오에 대해서 공부한다.

####빅 오 표기법
빅오는 시간 복잡도식에서 가장 영향력있는 것을 따로 표기하는 기법이다. 만약 n^2 + 2n + 1이라는 식이 있을때, 과연 어떤것이 가장 영향력 있을까? n^2이 가장 영향력이 있고 O(n^2)로 표기할 수 있다. 그렇다면 왜 다른것들은 영향력이 없다고 할까? 아래 예시를 보자
<pre><code>n = 10일 경우 n^2은 100, 2n = 20, n^2이 비율은 83.33%나 된다. 
만약 n =1000이라면 n^2은 1,000,000 2n = 2,000이고 n^2이 차지하는 비율은 99.80%나 된다
</code></pre>

위 내용을 보았듯이 엄청나게 많은 데이터를 삽입했을때, 영향력이 가장 큰 녀석을 따로 표현하여 알고리즘 성능을 결정 할 수 있고. 이렇게 결정된 것은 매우 확실하게 좋고 나쁜 알고리즘이라는 것을 한눈에 알 수 있다. 만약 뒤에 붙는 상수가 너무 큰 숫자라면 그 알고리즘은 평가 할 가치도 없으며, 쓰지 말아야하는 알고리즘이다.


